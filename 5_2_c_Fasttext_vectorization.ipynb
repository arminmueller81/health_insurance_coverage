{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Paper:\n",
    "# Text Mining and Document Classification Workflows for Chinese Administrative Documents\n",
    "\n",
    "## File 3 - Vectorization (fastText)\n",
    "\n",
    "This file tokenizes the data with Meta's fastText embeddings.\n",
    "\n",
    "## 1. Load packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # connection to OS\n",
    "import pandas as pd # data manipulation\n",
    "import numpy as np\n",
    "from ast import literal_eval # \n",
    "\n",
    "# Fasttext model\n",
    "import gensim\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python version: 3.8.18 (in Windows Subsystem for Linux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.24.3', '2.0.3')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# versions\n",
    "np.__version__, pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gensim version: 4.3.2\n"
     ]
    }
   ],
   "source": [
    "print(\"Gensim version:\", gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set working directory (for Windows Subsystem for Linux)\n",
    "os.chdir(\"working_directory_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "X_toksen_train = pd.read_csv('./y_broad/X_toksen_train.csv', converters={'tokenized_sen_filtered': literal_eval})\n",
    "X_toksen_test = pd.read_csv('./y_broad/X_toksen_test.csv', converters={'tokenized_sen_filtered': literal_eval})\n",
    "data_unlabelled = pd.read_csv('./data_unlabelled_tok_fil.csv', converters={'tokenized_sen_filtered': literal_eval})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up fastText model\n",
    "\n",
    "Load fastText Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path\n",
    "embeddings_path1 = \"/mnt/d/13b_language_models/cc.zh.300.bin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fasttext_model = FastText.load_fasttext_format(embeddings_path1)\n",
    "DeprecationWarning: Call to deprecated `load_fasttext_format` (use load_facebook_vectors (to use pretrained embeddings) or load_facebook_model (to continue training with the loaded full model, more RAM) instead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5660/3973388535.py:2: DeprecationWarning: Call to deprecated `load_fasttext_format` (use load_facebook_vectors (to use pretrained embeddings) or load_facebook_model (to continue training with the loaded full model, more RAM) instead).\n",
      "  fasttext_model = FastText.load_fasttext_format(embeddings_path1)\n"
     ]
    }
   ],
   "source": [
    "# load the model / the vectors\n",
    "fasttext_model = FastText.load_fasttext_format(embeddings_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.fasttext.FastText"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fasttext_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_toksen_train['tokenized_sen_filtered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the mean embedding for a list of words\n",
    "def calculate_mean_embedding(word_list, model):\n",
    "    return np.mean([model.wv[word] for word in word_list if word in model.wv], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convert data to fastText embeddings\n",
    "### 3.1 Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [加强, 部门, 间, 工作, 协同, 全面, 对接, 社会, 救助, 经办, 服务, 各地...\n",
       "1        [按规定, 定期, 社会, 公布, 基金, 收支, 情况, 参合, 人员, 待遇, 享受, ...\n",
       "2        [事实, 无人, 抚养, 儿童, 监护人, 受, 监护人, 委托, 近亲属, 填写, 事实,...\n",
       "3                    [慢性病, 种, 补偿, 名录, 呼吸系统, 慢性, 支气管炎, 肺气肿]\n",
       "4        [市, 外, 省内, 定点, 医疗机构, 住院, 医疗, 待遇, 起付, 标准, 支付, 比...\n",
       "                               ...                        \n",
       "13571                              [人民团体, 民主党派, 石嘴山市, 委员会]\n",
       "13572                                   [国家, 医疗, 保障局, 办公室]\n",
       "13573                                      [七年, 十一月, 二十九日]\n",
       "13574                               [分类管理, 提升, 供应, 保障, 水平]\n",
       "13575    [坚持, 完善, 覆盖, 全民, 依法, 参加, 基本, 医疗保险, 制度, 政策, 体系,...\n",
       "Name: tokenized_sen_filtered, Length: 13576, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_toksen_train['tokenized_sen_filtered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each element in the 'tokenized_sen_filtered' series\n",
    "train_embeddedFT1 = X_toksen_train['tokenized_sen_filtered'].apply(lambda x: calculate_mean_embedding(x, fasttext_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [-0.08964916, 0.03979323, 0.42967716, -0.04902...\n",
       "1        [-0.03411653, 0.046872012, 0.41202742, -0.0887...\n",
       "2        [-0.07017996, 0.0112573635, 0.3273037, -0.0663...\n",
       "3        [-0.020430032, -0.022946509, 0.28497145, 0.008...\n",
       "4        [0.13345155, 0.05627731, 0.3490851, -0.0545071...\n",
       "                               ...                        \n",
       "13571    [-0.042736597, -0.024878126, 0.10776475, -0.05...\n",
       "13572    [-0.023080138, 0.040626887, 0.38122424, -0.120...\n",
       "13573    [0.013475258, 0.06671035, 0.3204395, 0.0968477...\n",
       "13574    [-0.032232482, 0.0055650724, 0.36209345, 0.012...\n",
       "13575    [0.01714691, 0.045198016, 0.3901582, -0.094556...\n",
       "Name: tokenized_sen_filtered, Length: 13576, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the data\n",
    "train_embeddedFT1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the result to a NumPy array\n",
    "train_embeddedFT1 = np.array(train_embeddedFT1.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13576, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape\n",
    "train_embeddedFT1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "np.savetxt(\"./y_broad/train_embeddedFT_300.csv\", train_embeddedFT1, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_toksen_test['tokenized_sen_filtered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize Test data\n",
    "test_embeddedFT1 = X_toksen_test['tokenized_sen_filtered'].apply(lambda x: calculate_mean_embedding(x, fasttext_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [0.0419377, 0.05744974, 0.4677836, -0.02952056...\n",
       "1       [-0.005158877, 0.021575233, 0.2659846, -0.0599...\n",
       "2       [-0.015081197, -0.0019222625, 0.38544732, 0.04...\n",
       "3       [-0.026768051, 0.06382229, 0.42341638, -0.1173...\n",
       "4       [0.08470531, 0.049810894, 0.40017432, -0.03587...\n",
       "                              ...                        \n",
       "6683    [0.06798019, 0.060740087, 0.42204273, 0.000957...\n",
       "6684    [-0.085426144, 0.07721641, 0.468047, 0.0058804...\n",
       "6685    [0.0069559556, 0.07863893, 0.3840597, -0.03239...\n",
       "6686    [-0.07040116, 0.07836889, 0.39346752, -0.06034...\n",
       "6687    [-0.021006811, 0.0028569205, 0.24264129, -0.05...\n",
       "Name: tokenized_sen_filtered, Length: 6688, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the data\n",
    "test_embeddedFT1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the result to a NumPy array\n",
    "test_embeddedFT1 = np.array(test_embeddedFT1.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6688, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the dimensions\n",
    "test_embeddedFT1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "np.savetxt(\"./y_broad/test_embeddedFT_300.csv\", test_embeddedFT1, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Unlabelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [中外合资, 合作医疗, 机构, 管理, 暂行办法, 补充规定, 中华人民共和国, 卫生部,...\n",
       "1         [卫生部, 部长, 陈竺, 商务部, 部长, 陈德铭, ○, ○, 七年, 十二月, 三十日...\n",
       "2         [规定, 香港, 澳门, 服务提供者, 应, 符合, 内地, 香港, 建立, 紧密, 经贸关...\n",
       "3         [香港, 澳门, 服务提供者, 内地, 设立, 合资, 合作医疗, 机构, 规定, 参照, ...\n",
       "4                                              [规定, 日起, 施行]\n",
       "                                ...                        \n",
       "993521                                             [不予, 报销]\n",
       "993522    [第四章, 附则, 第二十四条, 技术, 方案, 八年, 六月, 一日, 统一, 执行, 原...\n",
       "993523    [第二十五条, 方案, 龙胜各族自治县, 新型农村, 合作医疗, 管理, 办公室, 负责, 解释]\n",
       "993524    [龙胜各族自治县, 人民政府, 成立, 自治县, 健康, 扶贫, ·, 医疗, 救助, 公益...\n",
       "993525                                 [龙胜各族自治县, 人民政府, 办公室]\n",
       "Name: tokenized_sen_filtered, Length: 993526, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_unlabelled['tokenized_sen_filtered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize unlabelled data\n",
    "unlabelled_embeddedFT1 = data_unlabelled['tokenized_sen_filtered'].apply(lambda x: calculate_mean_embedding(x, fasttext_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [-0.0444134, 0.018246418, 0.22672877, -0.06710...\n",
       "1         [0.023003206, -0.014322361, 0.27057192, -0.079...\n",
       "2         [0.053714447, -0.015653312, 0.3240408, -0.0817...\n",
       "3         [0.0039846506, -0.0053630774, 0.29727083, -0.1...\n",
       "4         [0.02381768, 0.052716304, 0.45353666, -0.23150...\n",
       "                                ...                        \n",
       "993521    [-0.0084002465, 0.05405068, 0.40219447, -0.030...\n",
       "993522    [0.0015540083, 0.095434986, 0.39776835, -0.087...\n",
       "993523    [-0.014256788, 0.030602433, 0.2537891, 0.00376...\n",
       "993524    [-0.014659241, 0.021233687, 0.3038526, -0.0527...\n",
       "993525    [-0.020915411, -0.0040786113, 0.102900915, -0....\n",
       "Name: tokenized_sen_filtered, Length: 993526, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the data\n",
    "unlabelled_embeddedFT1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the result to a NumPy array\n",
    "unlabelled_embeddedFT1 = np.array(unlabelled_embeddedFT1.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(993526,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dimensions\n",
    "unlabelled_embeddedFT1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "np.savetxt(\"./unlabelled_embeddedFT1.csv\", unlabelled_embeddedFT1, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WSLconpy38env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
